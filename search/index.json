[{"content":"La Tang Nano es una serie de placas de desarrollo FPGA desarrolladas por Sipeed, basadas en las FPGAs de Gowin, una empresa china reconocida por su bajo costo y alto rendimiento. En este tutorial, te mostraré cómo encender un LED utilizando la placa Tang Nano 9K, que cuenta con una FPGA GW1N-9K de Gowin, 9K LUTs, 240Kb de RAM, 128Kb de ROM, 2 PLLs y 2 SPIs. A través del IDE de Gowin, aprenderás a programar la placa y realizar una conexión sencilla para lograr este objetivo.\nPasos para encender un LED con la placa Tang Nano 9K:\nDescarga e instala el IDE de Gowin:\nVisita la página web de Gowin para descargar el IDE. La versión educativa es gratuita, pero también puedes solicitar una licencia gratuita de la versión profesional completando un registro. Crea un nuevo proyecto en el IDE:\nAbre el IDE de Gowin y selecciona la pestaña \u0026ldquo;File\u0026rdquo;. Haz clic en \u0026ldquo;New Project\u0026rdquo; y elige un nombre y una ubicación para tu proyecto, como \u0026ldquo;LED\u0026rdquo;. Asegúrate de guardar el proyecto en la carpeta de proyectos de Gowin. Selecciona el dispositivo adecuado:\nAl crear el proyecto, debes seleccionar el dispositivo que corresponda a tu versión de la placa Tang Nano. Para la Tang Nano 9K con FPGA GW1N-LV9QN48C6/I5, elige la opción correspondiente en el IDE. Crea un nuevo archivo Verilog:\nHaz clic en la pestaña \u0026ldquo;File\u0026rdquo; y selecciona \u0026ldquo;New File\u0026rdquo;. Nombre del archivo: \u0026ldquo;LED.v\u0026rdquo;. Guarda el archivo en la carpeta del proyecto. Escribe el código Verilog para encender el LED:\nAbre el archivo \u0026ldquo;LED.v\u0026rdquo; y escribe el siguiente código: 1 2 3 4 5 6 7 8 9 10 module LED( input btn, output reg led ); always @(posedge btn) begin led \u0026lt;= ~led; end endmodule Crea el archivo de mapeo de pines:\nUtiliza el FloorPlanner del IDE para crear el archivo de mapeo de pines. Ve a la pestaña \u0026ldquo;Tools\u0026rdquo; y selecciona \u0026ldquo;FloorPlanner\u0026rdquo;. Para el botón 1 es el pin 4 y el led 1 es el pin 10, esto se puede ver en el esquemático de la placa. Programa la FPGA:\nVe a la pestaña \u0026ldquo;Tools\u0026rdquo; y selecciona \u0026ldquo;Program Device\u0026rdquo;. Sigue las instrucciones para subir el programa a la FPGA. Observa el resultado:\nUna vez que el programa esté cargado en la FPGA, el LED 1 de la placa Tang Nano 9K se encenderá y apagará cada vez que presiones el botón 1. Ten en cuenta que los botones y LEDs en esta FPGA tienen un comportamiento inverso, lo que significa que el valor es 0 cuando se presiona un botón y 1 cuando no se presiona. Del mismo modo, cuando el valor es 0, el LED se enciende, y cuando el valor es 1, el LED se apaga. Para ajustar esto, se ha realizado una modificación en el código Verilog invirtiendo el valor predeterminado del LED.\n1 2 3 4 5 6 7 8 9 module LED( input btn, output reg led = 1 ); always @(posedge btn) begin led \u0026lt;= ~led; end endmodule Para los mas técnicos las configuración de los botones de la placa Tang Nano 9K están en pull-up y los leds se encuentran en ánodo común, esto se ve en el esquema de la placa:\nCon este tutorial, has aprendido cómo encender un LED utilizando la placa de desarrollo Tang Nano 9K de Sipeed. También has descubierto una característica importante de esta placa, en la que el funcionamiento de los LEDs integrados y los botones está invertido en comparación con la mayoría de las placas de desarrollo. ¡Explora más posibilidades y sigue experimentando con esta potente herramienta de desarrollo FPGA!\n","date":"2023-03-06T00:00:00Z","image":"https://fabianalvarez.dev/p/tang-nano-primero-pasos/cover_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://fabianalvarez.dev/p/tang-nano-primero-pasos/","title":"Tutorial: Encendiendo un LED con la placa de desarrollo Tang Nano 9K"},{"content":"Para el proyecto personal TinyTapeout 4, diseñé un ASIC Tamagotchi que reside en el chip. Dado el espacio limitado en el chip, este Tamagotchi es simple pero funcional. Además, representa un excelente punto de partida para aprender sobre el diseño de ASIC y explora conceptos interesantes, como la implementación de la comunicación serial UART y la generación de números pseudoaleatorios, que mencioné en un post anterior.\n# Acerca del Tamagotchi El diseño del Tamagotchi es muy sencillo. Consiste en una pequeña memoria que almacena caracteres en formato ASCII para permitir la representación gráfica del Tamagotchi en la consola serial. También incluye una lógica de control basada en máquinas de estados para mostrar diferentes animaciones que representan los estados del Tamagotchi. Además, cuenta con una especie de \u0026ldquo;barra de necesidades\u0026rdquo; que muestra sus estados de hambre, sueño y aburrimiento. Estas necesidades aumentan con el tiempo y pueden reducirse mediante la entrada de comandos desde el teclado, correspondientes a cada necesidad. En caso de que alguna de estas necesidades no se satisfaga adecuadamente, el Tamagotchi morirá y será necesario reiniciar el chip para jugar nuevamente, tal como sucede en un Tamagotchi real.\n# Diseño El corazón del Tamagotchi es, en gran medida, el generador de números pseudoaleatorios. Esto se debe a que controla cómo y cuáles de las estadísticas del Tamagotchi aumentarán de manera aparentemente \u0026ldquo;aleatoria\u0026rdquo;.\nEste diseño, a pesar de su simplicidad, abarca una serie de conceptos y funciones interesantes que hacen que el proyecto sea valioso tanto desde el punto de vista educativo como funcional. Además, el ASIC Tamagotchi en el chip es un proyecto creativo y entretenido que permite explorar la creación de un sistema embebido en un entorno de recursos limitados.\n# Generador de números pseudoaleatorios El generador de números pseudoaleatorios es un Linear Feedback Shift Register (LFSR) de 8 bits. El LFSR es un circuito secuencial que genera una secuencia de bits que se repite después de un cierto número de ciclos de reloj. La secuencia de bits generada por un LFSR parece aleatoria, pero en realidad es determinista y periódica. La longitud del período (el número de ciclos de reloj antes de que la secuencia se repita) depende de cómo se configure el LFSR, específicamente de qué bits se utilizan para la retroalimentación.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 module random( input wire clk, // Clock input input wire rst, // Reset input input wire [7:0] seed, // 8-bit seed input output wire [7:0] rand_out // 8-bit pseudo-random number output ); reg [7:0] lfsr_reg; // 8-bit register to hold the LFSR state always @(posedge clk or posedge rst) begin if (rst) begin lfsr_reg \u0026lt;= seed; // Initialize the LFSR with the seed end else begin // XOR feedback taps for an 8-bit LFSR: 8, 6, 5, 4 lfsr_reg \u0026lt;= {lfsr_reg[6:0], lfsr_reg[7] ^ lfsr_reg[4] ^ lfsr_reg[5] ^ lfsr_reg[3]}; end end assign rand_out = lfsr_reg; endmodule # Memoria de caracteres La memoria de caracteres es una memoria ROM de 8 bits que almacena caracteres en formato ASCII para permitir la representación gráfica del Tamagotchi en la consola serial. La memoria de caracteres es una memoria de solo lectura, por lo que los caracteres se cargan en la memoria durante la síntesis. La memoria de caracteres se implementa como una memoria de solo lectura de 8 bits con 256 palabras, donde cada palabra es un carácter ASCII de 8 bits. La memoria de caracteres se carga con los caracteres ASCII que representan las diferentes animaciones del Tamagotchi.\n# Comunicación serial UART La comunicación serial UART se implementa mediante una máquina de estados finitos (FSM) que controla la transmisión y recepción de datos. Use de base la transmisión que implemente en un post anterior\n# Lógica de control La logica de control es bastante simple en su concepto, para cada necesidad existe un registro que se va decrementando con el tiempo, cuando el registro llega a cero el Tamagotchi muere. Para evitar que el registro llegue a cero se puede ingresar un comando desde el teclado que aumenta el registro.\n","date":"2023-09-07T00:00:00Z","permalink":"https://fabianalvarez.dev/p/asic-tamagothi-un-proyecto-para-tinytapeout/","title":"ASIC Tamagothi un proyecto para TinyTapeout"},{"content":"En la actualidad la inteligencia artificial esta en todas partes, desde los asistentes de voz de los smartphones hasta los sistemas de reconocimiento facial de las redes sociales. En este post vamos a ver como crear un clasificador de imágenes con redes neuronales.\nComo lenguaje de programación vamos a usar Python ya que es uno de los lenguajes más populares para la inteligencia artificial. Para crear el clasificador de imágenes vamos a usar la librería Tensorflow-Keras, que es una librería de alto nivel que nos permite crear redes neuronales de forma sencilla. En especifico vamos a crear una CNN (Convolutional Neural Network).\n# ¿Que es una CNN? Una CNN es una red neuronal que se utiliza principalmente para clasificar imágenes. Una CNN es una red neuronal que tiene capas de convolución y capas de pooling. Las capas de convolución son capas que extraen características de las imágenes, mientras que las capas de pooling reducen la dimensionalidad de las imágenes.\n# ¿Que necesitamos para crear el clasificador de imágenes? Como todas las redes neuronales para entrenar se necesita un dataset, en este caso de imágenes, para entrenar vamos a utilizar una dataset real no una de ejemplo, ya que las de ejemplo se importan directamente al código y no muestra como se hace el preprocesamiento del dataset, que es uno de los pasos mas importantes para la creación de nuestro modelo, nuestro modelo es tan bueno como el dataset que le demos.\n# Preprocesamiento del dataset Vamos a descargar el dataset de clasificación de fabricación de kaggle que contiene ejemplos de piezas fabricadas en aluminio, donde se clasifican en 2 categorías diferentes, defectuosas y no defectuosas. El dataset contiene 3000 imágenes de 2 categorías diferentes, 1500 imágenes de piezas defectuosas y 1500 imágenes de piezas no defectuosas. El dataset esta dividido en 2 carpetas, una para las imágenes de entrenamiento y otra para las imágenes de prueba y dentro de cada carpeta hay 2 carpetas, una para las imágenes defectuosas y otra para las imágenes no defectuosas. De manera que el dataset tiene la siguiente estructura:\ndataset ├───train │ ├───def_front │ └───ok_front └───validation ├───def_front └───ok_front Con esto ya tenemos nuestro dataset, ahora vamos a crear nuestro modelo.\n# Creación del modelo Como la creación de los modelos de redes neuronales necesitan ejecutar bloques de código de manera repetitiva para encontrar el mejor modelo, vamos a usar google colab, que es un servicio de google que nos permite ejecutar código de manera remota en la nube, de manera que no necesitamos tener un ordenador con una GPU para entrenar nuestros modelos, ya que google colab nos permite usar una GPU de manera gratuita.\nComo mencione anteriormente vamos a usar Tensorflow-Keras, por lo cual vamos a importar las librerías necesarias para crear nuestro modelo.\n1 2 3 4 5 6 7 8 9 import tensorflow as tf from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.optimizers import RMSprop from tensorflow.keras.preprocessing import image import matplotlib.pyplot as plt import matplotlib.image as mpimg import os import random import numpy as np Importamos la librería de Tensorflow ademas de otras que nos serán útiles para el preprocesamiento del dataset y la visualización de las imágenes como el caso de matplotlib.\nComo mencione vamos a usar colab, por lo cual necesitamos subir nuestro dataset a colab, para reducir el tiempo de subida vamos a convertir nuestra carpeta de dataset en un zip y subirlo a Google Drive, al tenerlo ya en nuestro Drive vamos a descomprimirlo con la librería zipfile.\n1 2 3 import zipfile with zipfile.ZipFile(\u0026#34;/content/drive/MyDrive/IA/T.zip\u0026#34;,\u0026#34;r\u0026#34;) as zip_ref: zip_ref.extractall(\u0026#34;/content/drive/MyDrive/IA/\u0026#34;) Con esto ya tenemos nuestra carpeta de dataset descomprimida en nuestro Drive.\nAhora podemos proseguir con la creación de las clases del dataset, y con esto vemos la importancia de la estructura de nuestra carpeta del dataset, ya que keras nos permite crear las clases de manera automática, solo necesitamos especificar la ruta de la carpeta de entrenamiento y la carpeta de prueba. Iniciando con la carpeta de entrenamiento.\n1 2 3 4 5 6 train_ds = tf.keras.utils.image_dataset_from_directory( \u0026#39;/content/drive/MyDrive/IA/casting_data/train\u0026#39;, validation_split=0.2, subset=\u0026#34;training\u0026#34;, seed=123, image_size=(300,300)) Esta función tiene varios parámetros, el primero es la ruta de la carpeta de entrenamiento, el segundo es el porcentaje de imágenes que se van a usar para la validación, el tercero es el tipo de dataset, en este caso es de entrenamiento, el cuarto es la semilla para la generación de números aleatorios, y el último es el tamaño de las imágenes que vamos a usar, en este caso 300x300.\nAhora vamos con la dataset de validación.\n1 2 3 4 5 6 val_ds = tf.keras.utils.image_dataset_from_directory( \u0026#39;/content/drive/MyDrive/IA/T/train\u0026#39;, validation_split=0.2, subset=\u0026#34;validation\u0026#34;, seed=200, image_size=(300,300)) Esta función tiene los mismos parámetros que la anterior, solo cambia el tipo de dataset, en este caso es de validación, y la semilla para la generación de números aleatorios.\nSi imprimimos las clases creadas podemos ver el nombre de las clases y vemos que keras las ha creado de manera automática con el nombre de las carpetas.\n1 2 class_names = train_ds.class_names print(class_names) 1 [\u0026#39;def_front\u0026#39;, \u0026#39;ok_front\u0026#39;] Ahora vamos a visualizar algunas imágenes de nuestro dataset, para esto vamos a crear una función que nos permita visualizar las imágenes.\n1 2 3 4 5 6 7 8 9 import matplotlib.pyplot as plt # Importar la librería de matplolib para gráficas plt.figure(figsize=(10, 10)) for images, labels in train_ds.take(1): for i in range(9): ax = plt.subplot(3, 3, i + 1) plt.imshow(images[i].numpy().astype(\u0026#34;uint8\u0026#34;)) plt.title(class_names[labels[i]]) plt.axis(\u0026#34;off\u0026#34;) Ahora vamos a crear nuestro modelo.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 num_classes = len(class_names) model = Sequential([ layers.Rescaling(1./255, input_shape=(300, 300, 3)), layers.Conv2D(16, 3, padding=\u0026#39;same\u0026#39;, activation=\u0026#39;relu\u0026#39;), layers.MaxPooling2D(), layers.Conv2D(32, 3, padding=\u0026#39;same\u0026#39;, activation=\u0026#39;relu\u0026#39;), layers.MaxPooling2D(), layers.Conv2D(64, 3, padding=\u0026#39;same\u0026#39;, activation=\u0026#39;relu\u0026#39;), layers.MaxPooling2D(), layers.Flatten(), layers.Dense(128, activation=\u0026#39;relu\u0026#39;), layers.Dense(num_classes) ]) Este modelo tiene 10 capas, la primera capa es de normalización, la segunda es una capa de convolución con 16 filtros, la tercera es una capa de max pooling, la cuarta es una capa de convolución con 32 filtros, la quinta es una capa de max pooling, la sexta es una capa de convolución con 64 filtros, la séptima es una capa de max pooling, la octava es una capa de aplanamiento, la novena es una capa densa con 128 neuronas y la última es una capa densa con 2 neuronas, ya que tenemos 2 clases.\nEsta es la estructura básica de cualquier red CNN, la cual se compone de capas de convolución, capas de max pooling y finalmente capas densas.\nAhora compilamos el modelo.\n1 2 3 model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\u0026#39;accuracy\u0026#39;]) Para asegurarnos que todo salio bien vamos a imprimir el resumen del modelo.\n1 model.summary() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Model: \u0026#34;sequential_3\u0026#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= rescaling_5 (Rescaling) (None, 300, 300, 3) 0 conv2d_15 (Conv2D) (None, 300, 300, 16) 448 max_pooling2d_15 (MaxPoolin (None, 150, 150, 16) 0 g2D) conv2d_16 (Conv2D) (None, 150, 150, 32) 4640 max_pooling2d_16 (MaxPoolin (None, 75, 75, 32) 0 g2D) conv2d_17 (Conv2D) (None, 75, 75, 64) 18496 max_pooling2d_17 (MaxPoolin (None, 37, 37, 64) 0 g2D) flatten_5 (Flatten) (None, 87616) 0 dense_8 (Dense) (None, 128) 11214976 dense_9 (Dense) (None, 2) 258 ================================================================= Total params: 11,238,818 Trainable params: 11,238,818 Non-trainable params: 0 _________________________________________________________________ Ahora vamos a entrenar el modelo.\n1 2 3 4 5 6 epochs=4 history = model.fit( train_ds, validation_data=val_ds, epochs=epochs ) Vamos a iniciar el entrenamiento con 4 épocas, pero si queremos podemos aumentar el número de épocas para mejorar el modelo.\n# Evaluación del modelo Para evaluar un modelo tenemos dos métricas que nos pueden ayudar a saber si el modelo esta bien entrenado, estas son la precisión y la pérdida. Para entenderlas las graficaremos.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 acc = history.history[\u0026#39;accuracy\u0026#39;] val_acc = history.history[\u0026#39;val_accuracy\u0026#39;] loss = history.history[\u0026#39;loss\u0026#39;] val_loss = history.history[\u0026#39;val_loss\u0026#39;] epochs_range = range(epochs) plt.figure(figsize=(8, 8)) plt.subplot(1, 2, 1) plt.plot(epochs_range, acc, label=\u0026#39;Training Accuracy\u0026#39;) plt.plot(epochs_range, val_acc, label=\u0026#39;Validation Accuracy\u0026#39;) plt.legend(loc=\u0026#39;lower right\u0026#39;) plt.title(\u0026#39;Training and Validation Accuracy\u0026#39;) plt.subplot(1, 2, 2) plt.plot(epochs_range, loss, label=\u0026#39;Training Loss\u0026#39;) plt.plot(epochs_range, val_loss, label=\u0026#39;Validation Loss\u0026#39;) plt.legend(loc=\u0026#39;upper right\u0026#39;) plt.title(\u0026#39;Training and Validation Loss\u0026#39;) plt.show() En la gráfica de la izquierda podemos ver que la precisión de entrenamiento y en la de la derecha la pérdida de entrenamiento.\nPara interpretar estas gráficas podemos ver que la precisión de entrenamiento aumenta con cada época, pero la precisión de validación se estanca en 0.8, lo cual nos dice que el modelo esta sobreajustado, ya que no esta generalizando bien.\nDe la misma manera podemos ver que la pérdida de entrenamiento disminuye con cada época, pero la pérdida de validación se estanca en 0.4, lo cual nos dice que el modelo esta sobreajustado, ya que no esta generalizando bien.\nEn resumen entre mas cerca estén las lineas azules y naranjas, mejor es el modelo. En este caso hay un pequeño sobreajuste, pero no es tan grave.\nCon esto podemos finalizar el modelo, ahora vamos a evaluarlo con datos que no ha visto.\n1 2 3 4 test_ds = tf.keras.utils.image_dataset_from_directory( \u0026#39;/content/drive/MyDrive/IA/casting_data/test\u0026#39;, seed=123, image_size=(300,300)) creamos un dataset de validación y evaluamos el modelo.\n1 model.evaluate(test_ds,return_dict=True) Esto nos devuelve un diccionario con las métricas que definimos al compilar el modelo, en este caso la precisión y la pérdida.\n1 2 23/23 [==============================] - 66s 2s/step - loss: 0.0397 - accuracy: 0.9902 {\u0026#39;loss\u0026#39;: 0.039654314517974854, \u0026#39;accuracy\u0026#39;: 0.9902098178863525} Vemos entonces que la precisión es de 0.99 y la pérdida es de 0.04, lo cual es muy bueno.\n# Predicción Ahora vamos a probar el modelo con una imagen que no ha visto y que seria una entrada del modelo en la vida real.\n1 2 3 4 5 image_path = \u0026#39;/content/drive/MyDrive/IA/casting_data/test/def_front/cast_def_0_1189.jpeg\u0026#39; image = tf.keras.preprocessing.image.load_img(image_path) input_arr = tf.keras.preprocessing.image.img_to_array(image) input_arr = np.array([input_arr]) # Convert single image to a batch. predictions = model.predict(input_arr) Todo esto es para convertir la imagen en un array de numpy y poder predecir con el modelo ya que en realidad los modelos no se entrenan con imagenes, sino con arrays que componen las imagenes. Ahora vemos la predicción.\n1 2 3 4 5 score = tf.nn.softmax(predictions[0]) print( \u0026#34;Esta imagen parece ser {} con un {:.2f} % de exactitud.\u0026#34; .format(class_names[np.argmax(score)], 100 * np.max(score)) ) 1 Esta imagen parece ser def_front con un 100.00 % de exactitud. Lo cual es correcto, ya que la imagen es de un defecto frontal. Con esto finalmente podemos decir que el modelo esta listo para ser usado en la vida real. Ahora lo guardamos para poder usarlo en el futuro.\n1 model.save(\u0026#39;/content/drive/MyDrive/IA/casting_data/model\u0026#39;) Para cargar el modelo en el futuro solo tenemos que hacer lo siguiente.\n1 model = tf.keras.models.load_model(\u0026#39;/content/drive/MyDrive/IA/casting_data/model\u0026#39;) # Extra Como mencione este modelo tiene un sobreajuste, pero no es tan grave, para mejorar el modelo podemos hacer lo siguiente:\nAumentar el número de épocas. Agregar más datos de entrenamiento. Agregar dropout. Una solución para el sobreajuste es el dropout, que consiste en eliminar aleatoriamente neuronas de la red, para que no se sobreajusten. Para agregarlo solo tenemos que agregar una capa de dropout después de cada capa de flatten y antes de las capas densas, dropout de 0.2, lo cual significa que el 20% de las neuronas serán eliminadas aleatoriamente.\n1 2 3 4 5 6 7 8 9 10 11 12 13 model = Sequential([ layers.Rescaling(1./255, input_shape=(300, 300, 3)), layers.Conv2D(16, 3, padding=\u0026#39;same\u0026#39;, activation=\u0026#39;relu\u0026#39;), layers.MaxPooling2D(), layers.Conv2D(32, 3, padding=\u0026#39;same\u0026#39;, activation=\u0026#39;relu\u0026#39;), layers.MaxPooling2D(), layers.Conv2D(64, 3, padding=\u0026#39;same\u0026#39;, activation=\u0026#39;relu\u0026#39;), layers.MaxPooling2D(), layers.Flatten(), layers.Dropout(0.2), layers.Dense(128, activation=\u0026#39;relu\u0026#39;), layers.Dense(num_classes) ]) Hacemos los mismo pasos para compilar y entrenar el modelo, esta vez nos da las siguientes métricas.\nDonde se ve que al final las dos lineas son casi iguales, lo cual significa que no hay sobreajuste. Ahora evaluamos el modelo con los datos de validación.\n1 2 3 final.evaluate(test_ds,return_dict=True) 23/23 [==============================] - 19s 815ms/step - loss: 0.0224 - accuracy: 0.9958 {\u0026#39;loss\u0026#39;: 0.02243557944893837, \u0026#39;accuracy\u0026#39;: 0.9958041906356812} Con esto terminamos el tutorial, espero que les haya gustado y que les sirva para sus proyectos.\n","date":"2023-08-07T00:00:00Z","permalink":"https://fabianalvarez.dev/p/como-crear-un-clasificador-de-imagenes-con-redes-neuronales/","title":"Como crear un clasificador de imagenes con redes neuronales"},{"content":"Generar números aleatorios es imposible, por lo menos en el ámbito computacional, claramente en muchos lenguajes de programación existen las funciones random, lo que hacen estas funciones es generar números pseudo-aleatorios y eso es lo que vamos a hacer\nEn verilog también existe una función para generar números pseudo-aleatorios, la función es $random, esta función solo es para simulación no para implementación, por lo que no nos sirve para lo que queremos hacer. {:.warning}\nDerivando tiene un video que lo explica mucho mejor.\n{%- include extensions/youtube.html id='RzEjqJHW-NU' -%} Para generar los números pseudo-aleatorios vamos a usar un linear-feedback shift register o LFSR, para la generación se usan los siguientes pasos:\nRegistro de Desplazamiento: Un LFSR consta de un registro de desplazamiento que contiene una serie de bits. Los bits se desplazan hacia la derecha (o izquierda) en cada ciclo de reloj.\nRetroalimentación Lineal: La característica principal de un LFSR es que algunos de los bits del registro se combinan mediante operaciones lógicas (generalmente XOR) y se retroalimentan en la entrada. Estos bits se denominan \u0026ldquo;taps\u0026rdquo; o \u0026ldquo;retroalimentaciones\u0026rdquo;.\nCiclo de Reloj: En cada ciclo de reloj, todos los bits en el registro se desplazan hacia la derecha (o izquierda) en una posición. El valor del nuevo bit de entrada (el que ingresa en el registro) se calcula a partir de la retroalimentación de los bits existentes en el registro según las reglas de retroalimentación definidas. Esto es lo que hace que el registro de desplazamiento sea \u0026ldquo;lineal\u0026rdquo;.\nSecuencia Pseudoaleatoria: La secuencia de bits generada por un LFSR parece aleatoria, pero en realidad es determinista y periódica. La longitud del período (el número de ciclos de reloj antes de que la secuencia se repita) depende de cómo se configure el LFSR, específicamente de qué bits se utilizan para la retroalimentación.\nSalida: Puedes considerar la salida del LFSR como el bit más a la derecha en el registro de desplazamiento. Este bit se toma como la salida de la secuencia pseudoaleatoria. La secuencia de bits en esta salida se repite después de un cierto número de ciclos, pero puede parecer muy aleatoria durante ese período.\n# Implementación Para implementar el LFSR vamos a usar el siguiente código:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 module random( input wire clk, // Clock input input wire rst, // Reset input output wire [7:0] rand_out // 8-bit pseudo-random number output ); reg [7:0] lfsr_reg; // 8-bit register to hold the LFSR state always @(posedge clk or posedge rst) begin if (rst) begin lfsr_reg \u0026lt;= 8\u0026#39;b1111_1111; // Initialize LFSR with all ones end else begin // XOR feedback taps for an 8-bit LFSR: 8, 6, 5, 4 lfsr_reg \u0026lt;= {lfsr_reg[6:0], lfsr_reg[7] ^ lfsr_reg[4] ^ lfsr_reg[5] ^ lfsr_reg[3]}; end end assign rand_out = lfsr_reg; endmodule Este código es para un LFSR de 8 bits, si quieres un LFSR de 16 bits solo tienes que cambiar el tamaño del registro y los taps, para un LFSR de 16 bits los taps son 16, 14, 13, 11.\nEl código es bastante simple, se compone de en realidad solo dos operaciones el desplazamiento y el XOR, el desplazamiento se hace con {lfsr_reg[6:0], lfsr_reg[7]} y el XOR con lfsr_reg[7] ^ lfsr_reg[4] ^ lfsr_reg[5] ^ lfsr_reg[3]. También tiene el reset que inicializa el registro con todos unos\nEl valor de reset sirve también como semilla de nuestro generador de números pseudo-aleatorios {:.info}\n","date":"2023-07-08T00:00:00Z","permalink":"https://fabianalvarez.dev/p/tutorial-como-generar-n%C3%BAmeros-aleatorios-en-una-fpga/","title":"Tutorial: Como generar números aleatorios en una FPGA"},{"content":" # Introducción La comunicación UART es una de las más utilizadas en el mundo de la electrónica, ya que es una de las más sencillas de implementar y es muy útil para la comunicación entre dispositivos. En este tutorial aprenderás a implementar la comunicación UART en una FPGA, utilizando el lenguaje de descripción de hardware Verilog.\n# ¿Cómo funciona la comunicación UART? La comunicación UART es una comunicación asíncrona, lo que significa que no se necesita un reloj para sincronizar los datos. En su lugar, se utiliza un bit de inicio y un bit de parada para sincronizar los datos. La comunicación UART se basa en el envío de bytes, que son paquetes de 8 bits (puede variar pero 8 bits es la mas extendida). Cada byte se envía en serie, es decir, un bit a la vez. El bit de inicio es un bit de nivel bajo que indica que se va a enviar un byte. El bit de parada es un bit de nivel alto que indica que se ha terminado de enviar el byte. Entre el bit de inicio y el bit de parada se envían los 8 bits del byte. La siguiente imagen muestra un ejemplo de la comunicación UART.\n# Baudrate El baudrate es la velocidad a la que se envían los datos. Se mide en baudios, que es el número de bits que se envían por segundo. Por ejemplo, si el baudrate es de 9600 baudios, se envían 9600 bits por segundo. El baudrate se puede calcular con la siguiente fórmula:\n$$baudrate = \\frac{\\text{Frecuencia del reloj}}{\\text{divisiones de relog}}$$\nEl baudrate tiene valores estandar por lo cual lo que se calcula en realidad son las divisiones de reloj, lo cual cambia la formula a la siguiente:\n$$\\text{divisiones de reloj} = \\frac{\\text{Frecuencia del reloj}}{\\text{baudrate}}$$\nPara un reloj de 27 Mhz a un baudrate de 115200, las divisiones de reloj serían:\n$$\\text{divisiones de reloj} = \\frac{27 \\text{ Mhz}}{115200} = 234.375$$\nComo las divisiones de reloj es un numero entero, el resultado se redondea a 234. Por lo tanto, para un reloj de 27 Mhz a un baudrate de 115200, las divisiones de reloj serían 234.\n# Leer datos de la UART Para leer datos de la UART, se debe leer el bit de inicio, los 8 bits del byte y el bit de parada. Para la lectura y asegurarnos de leer correctamente los datos de la UART, se debe utilizar un reloj que sea 16 veces más rápido que el baudrate. Por ejemplo, si el baudrate es de 115200, el reloj debe ser de 1843200 Hz. Esto se debe a que se deben leer 10 bits (1 bit de inicio, 8 bits del byte y 1 bit de parada) y el reloj debe ser 16 veces más rápido que el baudrate. La lectura no se hace 16 veces por segundo, sino que se lee un bit cada 8 ciclos de reloj para asegurarnos que leemos el dato en la mitad del tiempo que tarda en llegar el siguiente bit. La siguiente imagen muestra un ejemplo de la lectura de datos de la UART.\n# Escribir datos en la UART La escritura es simular a la lectura, para escribir datos en la UART, se debe escribir el bit de inicio, los 8 bits del byte y el bit de parada. Para la escritura y asegurarnos de escribir correctamente los datos en la UART, se debe utilizar un reloj que sea 16 veces más rápido que el baudrate. Esto se debe a que se deben escribir 10 bits (1 bit de inicio, 8 bits del byte y 1 bit de parada) al igual que en la lectura. La escritura no se hace 16 veces por segundo, sino que se escribe un bit cada 8 ciclos de reloj para asegurarnos que escribimos el dato en la mitad del tiempo que tarda en llegar el siguiente bit. Ambos procesos (lectura y escritura) se pueden hacer con al mismo tiempo ya que son independientes entre si y por cables diferentes.\n# Implementación en Verilog A continuación se muestra el código en Verilog para implementar la comunicación UART en una FPGA. El código se puede descargar desde Github\n# Maquina de estados Para implementar la comunicación UART vamos a usar dos maquinas de estados, una para la lectura y otra para la escritura. La maquina de estados para la lectura se llama RX y la maquina de estados para la escritura se llama TX. Ambas maquinas de estados se ejecutan al mismo tiempo ya que son independientes entre si y por cables diferentes.\n# Maquina de estados RX Esta maquina tienen 5 estados, IDLE, START_BIT, READ_WAIT, READ y STOP_BIT. El estado IDLE es el estado inicial y se queda en este estado hasta que se detecta el bit de inicio. Cuando se detecta el bit de inicio, se pasa al estado START_BIT y se empieza a leer los 8 bits del byte, con el estado intermedio READ_WAIT que hace la division en 16 partes como explique en la teoría. Cuando se termina de leer los 8 bits del byte, se pasa al estado STOP_BIT y se espera a que llegue el bit de parada. Cuando se detecta el bit de parada, se pasa al estado IDLE y se termina la lectura del byte.\nNota: Usamos el localparam HALF_DELAY_WAIT y el DELAY_FRAMES para hacer la division en 16 partes. El DELAY_FRAMES es el numero de ciclos de reloj que se espera en el estado READ_WAIT y el HALF_DELAY_WAIT es la mitad del DELAY_FRAMES. El DELAY_FRAMES se calcula con la formula que mostré en la teoría.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 localparam RX_STATE_IDLE = 0; localparam RX_STATE_START_BIT = 1; localparam RX_STATE_READ_WAIT = 2; localparam RX_STATE_READ = 3; localparam RX_STATE_STOP_BIT = 5; always @(posedge clk) begin case (rxState) RX_STATE_IDLE: begin if (uart_rx == 0) begin rxState \u0026lt;= RX_STATE_START_BIT; rxCounter \u0026lt;= 1; rxBitNumber \u0026lt;= 0; byteReady \u0026lt;= 0; end end RX_STATE_START_BIT: begin if (rxCounter == HALF_DELAY_WAIT) begin rxState \u0026lt;= RX_STATE_READ_WAIT; rxCounter \u0026lt;= 1; end else rxCounter \u0026lt;= rxCounter + 1; end RX_STATE_READ_WAIT: begin rxCounter \u0026lt;= rxCounter + 1; if ((rxCounter + 1) == DELAY_FRAMES) begin rxState \u0026lt;= RX_STATE_READ; end end RX_STATE_READ: begin rxCounter \u0026lt;= 1; dataIn \u0026lt;= {uart_rx, dataIn[7:1]}; rxBitNumber \u0026lt;= rxBitNumber + 1; if (rxBitNumber == 3\u0026#39;b111) rxState \u0026lt;= RX_STATE_STOP_BIT; else rxState \u0026lt;= RX_STATE_READ_WAIT; end RX_STATE_STOP_BIT: begin rxCounter \u0026lt;= rxCounter + 1; if ((rxCounter + 1) == DELAY_FRAMES) begin rxState \u0026lt;= RX_STATE_IDLE; rxCounter \u0026lt;= 0; byteReady \u0026lt;= 1; end end endcase end # Maquina de estados TX Con una aproximación similar realizamos la maquina de estados para la escritura. Esta maquina tienen 5 estados, IDLE, START_BIT, WRITE , STOP_BIT y por ultimo DEBOUNCE que es el estado diferente, este estado lo que hace es mantener en alto la salida, lo que indica que no se están enviando datos, recordemos que el start bit es un bit de nivel bajo.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 localparam TX_STATE_IDLE = 0; localparam TX_STATE_START_BIT = 1; localparam TX_STATE_WRITE = 2; localparam TX_STATE_STOP_BIT = 3; localparam TX_STATE_DEBOUNCE = 4; always @(posedge clk) begin case (txState) TX_STATE_IDLE: begin if (btn1 == 0) begin txState \u0026lt;= TX_STATE_START_BIT; txCounter \u0026lt;= 0; txByteCounter \u0026lt;= 0; end else begin txPinRegister \u0026lt;= 1; end end TX_STATE_START_BIT: begin txPinRegister \u0026lt;= 0; if ((txCounter + 1) == DELAY_FRAMES) begin txState \u0026lt;= TX_STATE_WRITE; dataOut \u0026lt;= testMemory[txByteCounter]; txBitNumber \u0026lt;= 0; txCounter \u0026lt;= 0; end else txCounter \u0026lt;= txCounter + 1; end TX_STATE_WRITE: begin txPinRegister \u0026lt;= dataOut[txBitNumber]; if ((txCounter + 1) == DELAY_FRAMES) begin if (txBitNumber == 3\u0026#39;b111) begin txState \u0026lt;= TX_STATE_STOP_BIT; end else begin txState \u0026lt;= TX_STATE_WRITE; txBitNumber \u0026lt;= txBitNumber + 1; end txCounter \u0026lt;= 0; end else txCounter \u0026lt;= txCounter + 1; end TX_STATE_STOP_BIT: begin txPinRegister \u0026lt;= 1; if ((txCounter + 1) == DELAY_FRAMES) begin if (txByteCounter == MEMORY_LENGTH - 1) begin txState \u0026lt;= TX_STATE_DEBOUNCE; end else begin txByteCounter \u0026lt;= txByteCounter + 1; txState \u0026lt;= TX_STATE_START_BIT; end txCounter \u0026lt;= 0; end else txCounter \u0026lt;= txCounter + 1; end TX_STATE_DEBOUNCE: begin if (txCounter == 23\u0026#39;b111111111111111111) begin if (btn1 == 1) txState \u0026lt;= TX_STATE_IDLE; end else txCounter \u0026lt;= txCounter + 1; end endcase end # Led de estado Para verificar que nuestra comunicacion este funcionando para ambos sentidos, debido a que cada cable es independiente, usamos los leds integrados de en mi caso la FPGA Tang Nano 9K. Para esto usamos el siguiente codigo:\n1 2 3 4 5 always @(posedge clk) begin if (byteReady) begin led \u0026lt;= ~dataIn[5:0]; end end Nota: dataIn es el byte que se recibe de la UART y sale de la maquina de estados RX, para la tang nano 9k el led es activo bajo, por lo cual se debe negar el byte para que se encienda el led.\nPara verificar el envio de datos vamos a usar el puerto serial para leer los datos, vamos a crear un arreglo de datos para enviar y lo vamos a enviar cada vez que se presione el boton 1. Para esto usamos el siguiente codigo:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 reg [3:0] txState = 0; reg [24:0] txCounter = 0; reg [7:0] dataOut = 0; reg txPinRegister = 1; reg [2:0] txBitNumber = 0; reg [4:0] txByteCounter = 0; assign uart_tx = txPinRegister; localparam MEMORY_LENGTH = 18; reg [7:0] testMemory [MEMORY_LENGTH-1:0]; initial begin testMemory[0] = \u0026#34;F\u0026#34;; testMemory[1] = \u0026#34;a\u0026#34;; testMemory[2] = \u0026#34;b\u0026#34;; testMemory[3] = \u0026#34;i\u0026#34;; testMemory[4] = \u0026#34;a\u0026#34;; testMemory[5] = \u0026#34;n\u0026#34;; testMemory[6] = \u0026#34;a\u0026#34;; testMemory[7] = \u0026#34;l\u0026#34;; testMemory[8] = \u0026#34;v\u0026#34;; testMemory[9] = \u0026#34;a\u0026#34;; testMemory[10] = \u0026#34;r\u0026#34;; testMemory[11] = \u0026#34;e\u0026#34;; testMemory[12] = \u0026#34;z\u0026#34;; testMemory[13] = \u0026#34;.\u0026#34;; testMemory[14] = \u0026#34;d\u0026#34;; testMemory[15] = \u0026#34;e\u0026#34;; testMemory[16] = \u0026#34;v\u0026#34;; testMemory[17] = \u0026#34; \u0026#34;; end y con esto ya tenemos nuestra comunicación UART implementada en Verilog.\n# Pinout de la FPGA En una FPGA cualquier pin sirve como RX y TX, en el caso de la Tang Nano 9K tiene una conexion directa con el puerto usb, por lo cual se puede conectar directamente a la computadora y usar el puerto serial para leer y escribir datos. En el caso de la Tang Nano 9K, el pin RX es el pin 18 y el pin TX es el pin 17. La siguiente imagen muestra el pinout de la Tang Nano 9K. # Conclusión En este tutorial, has aprendido a implementar la comunicación UART en una FPGA utilizando el lenguaje de descripción de hardware Verilog. Comprendes cómo funciona la comunicación UART, cómo leer y escribir datos, y cómo implementarla en Verilog. Además, has aprendido a utilizar los LEDs integrados en la FPGA para verificar el funcionamiento de la comunicación. Si tienes alguna pregunta, no dudes en dejar un comentario, y estaré encantado de ayudarte a resolverla. ¡Buena suerte en tu proyecto de FPGA!\n# Codigo completo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 `default_nettype none module top #( parameter DELAY_FRAMES = 234 // 27,000,000 (27Mhz) / 115200 Baud rate ) ( input clk, input uart_rx, output uart_tx, output reg [5:0] led, input btn1 ); localparam HALF_DELAY_WAIT = (DELAY_FRAMES / 2); reg [3:0] rxState = 0; reg [12:0] rxCounter = 0; reg [7:0] dataIn = 0; reg [2:0] rxBitNumber = 0; reg byteReady = 0; localparam RX_STATE_IDLE = 0; localparam RX_STATE_START_BIT = 1; localparam RX_STATE_READ_WAIT = 2; localparam RX_STATE_READ = 3; localparam RX_STATE_STOP_BIT = 5; always @(posedge clk) begin case (rxState) RX_STATE_IDLE: begin if (uart_rx == 0) begin rxState \u0026lt;= RX_STATE_START_BIT; rxCounter \u0026lt;= 1; rxBitNumber \u0026lt;= 0; byteReady \u0026lt;= 0; end end RX_STATE_START_BIT: begin if (rxCounter == HALF_DELAY_WAIT) begin rxState \u0026lt;= RX_STATE_READ_WAIT; rxCounter \u0026lt;= 1; end else rxCounter \u0026lt;= rxCounter + 1; end RX_STATE_READ_WAIT: begin rxCounter \u0026lt;= rxCounter + 1; if ((rxCounter + 1) == DELAY_FRAMES) begin rxState \u0026lt;= RX_STATE_READ; end end RX_STATE_READ: begin rxCounter \u0026lt;= 1; dataIn \u0026lt;= {uart_rx, dataIn[7:1]}; rxBitNumber \u0026lt;= rxBitNumber + 1; if (rxBitNumber == 3\u0026#39;b111) rxState \u0026lt;= RX_STATE_STOP_BIT; else rxState \u0026lt;= RX_STATE_READ_WAIT; end RX_STATE_STOP_BIT: begin rxCounter \u0026lt;= rxCounter + 1; if ((rxCounter + 1) == DELAY_FRAMES) begin rxState \u0026lt;= RX_STATE_IDLE; rxCounter \u0026lt;= 0; byteReady \u0026lt;= 1; end end endcase end always @(posedge clk) begin if (byteReady) begin led \u0026lt;= ~dataIn[5:0]; end end reg [3:0] txState = 0; reg [24:0] txCounter = 0; reg [7:0] dataOut = 0; reg txPinRegister = 1; reg [2:0] txBitNumber = 0; reg [4:0] txByteCounter = 0; assign uart_tx = txPinRegister; localparam MEMORY_LENGTH = 18; reg [7:0] testMemory [MEMORY_LENGTH-1:0]; initial begin testMemory[0] = \u0026#34;F\u0026#34;; testMemory[1] = \u0026#34;a\u0026#34;; testMemory[2] = \u0026#34;b\u0026#34;; testMemory[3] = \u0026#34;i\u0026#34;; testMemory[4] = \u0026#34;a\u0026#34;; testMemory[5] = \u0026#34;n\u0026#34;; testMemory[6] = \u0026#34;a\u0026#34;; testMemory[7] = \u0026#34;l\u0026#34;; testMemory[8] = \u0026#34;v\u0026#34;; testMemory[9] = \u0026#34;a\u0026#34;; testMemory[10] = \u0026#34;r\u0026#34;; testMemory[11] = \u0026#34;e\u0026#34;; testMemory[12] = \u0026#34;z\u0026#34;; testMemory[13] = \u0026#34;.\u0026#34;; testMemory[14] = \u0026#34;d\u0026#34;; testMemory[15] = \u0026#34;e\u0026#34;; testMemory[16] = \u0026#34;v\u0026#34;; testMemory[17] = \u0026#34; \u0026#34;; end localparam TX_STATE_IDLE = 0; localparam TX_STATE_START_BIT = 1; localparam TX_STATE_WRITE = 2; localparam TX_STATE_STOP_BIT = 3; localparam TX_STATE_DEBOUNCE = 4; always @(posedge clk) begin case (txState) TX_STATE_IDLE: begin if (btn1 == 0) begin txState \u0026lt;= TX_STATE_START_BIT; txCounter \u0026lt;= 0; txByteCounter \u0026lt;= 0; end else begin txPinRegister \u0026lt;= 1; end end TX_STATE_START_BIT: begin txPinRegister \u0026lt;= 0; if ((txCounter + 1) == DELAY_FRAMES) begin txState \u0026lt;= TX_STATE_WRITE; dataOut \u0026lt;= testMemory[txByteCounter]; txBitNumber \u0026lt;= 0; txCounter \u0026lt;= 0; end else txCounter \u0026lt;= txCounter + 1; end TX_STATE_WRITE: begin txPinRegister \u0026lt;= dataOut[txBitNumber]; if ((txCounter + 1) == DELAY_FRAMES) begin if (txBitNumber == 3\u0026#39;b111) begin txState \u0026lt;= TX_STATE_STOP_BIT; end else begin txState \u0026lt;= TX_STATE_WRITE; txBitNumber \u0026lt;= txBitNumber + 1; end txCounter \u0026lt;= 0; end else txCounter \u0026lt;= txCounter + 1; end TX_STATE_STOP_BIT: begin txPinRegister \u0026lt;= 1; if ((txCounter + 1) == DELAY_FRAMES) begin if (txByteCounter == MEMORY_LENGTH - 1) begin txState \u0026lt;= TX_STATE_DEBOUNCE; end else begin txByteCounter \u0026lt;= txByteCounter + 1; txState \u0026lt;= TX_STATE_START_BIT; end txCounter \u0026lt;= 0; end else txCounter \u0026lt;= txCounter + 1; end TX_STATE_DEBOUNCE: begin if (txCounter == 23\u0026#39;b111111111111111111) begin if (btn1 == 1) txState \u0026lt;= TX_STATE_IDLE; end else txCounter \u0026lt;= txCounter + 1; end endcase end endmodule ","date":"2023-06-06T00:00:00Z","permalink":"https://fabianalvarez.dev/p/tutorial-implementar-comunicaci%C3%B3n-uart-en-fpga/","title":"Tutorial: Implementar comunicación UART en FPGA"}]